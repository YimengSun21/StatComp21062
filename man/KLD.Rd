% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/KLD.R
\name{KLD}
\alias{KLD}
\title{Kullback-Leibler divergence(KLD)}
\usage{
KLD(px, py, base = exp(1))
}
\arguments{
\item{px}{discrete probability distributions}

\item{py}{discrete probability distributions}

\item{base}{the logarithmic base, defaults to \code{e}=exp(1)}
}
\value{
forward Kullback-Leibler divergence and 
backward Kullback-Leibler divergence of discrete probability distributions p and q
}
\description{
Calculate the Kullback-Leibler divergence between two probability distributions.
}
\examples{
\dontrun{
p <- c(105,24,10,2,120,56)
q <- c(1,4,8,15,200,78)
KLD(p, q)
KLD(p, q, base = exp(1))
KLD(p, q, base = 2)
}
}
